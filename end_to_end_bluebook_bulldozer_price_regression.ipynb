{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "colab": {
      "name": "end-to-end-bluebook-bulldozer-price-regression.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWye40h1DEnN"
      },
      "source": [
        "# Predicting the Sale Price of Bulldozers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9_C-CXaDEnR"
      },
      "source": [
        "## 1. Problem Definition\n",
        "\n",
        "For this dataset, the problem we're trying to solve, or better, the question we're trying to answer is,\n",
        "\n",
        "> How well can we predict the future sale price of a bulldozer, given its characteristics previous examples of how much similar bulldozers have been sold for?\n",
        "\n",
        "## 2. Data\n",
        "\n",
        "\n",
        "There are 3 datasets:\n",
        "1. **Train.csv** - Historical bulldozer sales examples up to 2011 (close to 400,000 examples with 50+ different attributes, including `SalePrice` which is the **target variable**).\n",
        "2. **Valid.csv** - Historical bulldozer sales examples from January 1 2012 to April 30 2012 (close to 12,000 examples with the same attributes as **Train.csv**).\n",
        "3. **Test.csv** - Historical bulldozer sales examples from May 1 2012 to November 2012 (close to 12,000 examples but missing the `SalePrice` attribute, as this is what we'll be trying to predict).\n",
        "\n",
        "## 3. Evaluation\n",
        "\n",
        "For this problem, [Kaggle has set the evaluation metric to being root mean squared log error (RMSLE)](https://www.kaggle.com/c/bluebook-for-bulldozers/overview/evaluation).\n",
        "\n",
        "\n",
        "\n",
        "## 4. Features\n",
        "\n",
        "Features are different parts of the data. During this step, you'll want to start finding out what you can about the data.\n",
        "\n",
        "One of the most common ways to do this, is to create a **data dictionary**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1t6rvSfDEnT"
      },
      "source": [
        "### Importing the data and preparing it for modelling\n",
        "\n",
        "Now we've got our tools for data analysis ready, we can import the data and start to explore it.\n",
        "\n",
        "For this project, we've [downloaded the data from Kaggle](https://www.kaggle.com/c/bluebook-for-bulldozers/data) and stored it under the file path `\"../data/\"`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-b4jp-2DEnS"
      },
      "source": [
        "# Import data analysis tools \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hplHfRhDEnT"
      },
      "source": [
        "# Import the training and validation set\n",
        "df = pd.read_csv(\"../data/bluebook-for-bulldozers/TrainAndValid.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9jUx3baDEnU"
      },
      "source": [
        "# No parse_dates... check dtype of \"saledate\"\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mlLWefGDEnV"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(df[\"saledate\"][:1000], df[\"SalePrice\"][:1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eauQM9iJDEnW"
      },
      "source": [
        "df.SalePrice.plot.hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hcEF9zODEnW"
      },
      "source": [
        "### Parsing dates\n",
        "When working with time series data, it's a good idea to make sure any date data is the format of a [datetime object](https://docs.python.org/3/library/datetime.html) (a Python data type which encodes specific information about dates)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVg3KMw9DEnX"
      },
      "source": [
        "df = pd.read_csv(\"../data/bluebook-for-bulldozers/TrainAndValid.csv\",\n",
        "                 low_memory=False,\n",
        "                 parse_dates=[\"saledate\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFAkUhfYDEnX"
      },
      "source": [
        "# With parse_dates... check dtype of \"saledate\"\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKOY1cAXDEnX"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(df[\"saledate\"][:1000], df[\"SalePrice\"][:1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkWSt2MMDEnY"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dULWbZYLDEnY"
      },
      "source": [
        "df.head().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTQ_rk3ZDEnZ"
      },
      "source": [
        "df.saledate.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxiYDSGBDEnZ"
      },
      "source": [
        "### Sort DataFrame by saledate\n",
        "\n",
        "As we're working on a time series problem and trying to predict future examples given past examples, it makes sense to sort our data by date."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJsJviW4DEnZ"
      },
      "source": [
        "# Sort DataFrame in date order\n",
        "df.sort_values(by=[\"saledate\"], inplace=True, ascending=True)\n",
        "df.saledate.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlWPMNQYDEna"
      },
      "source": [
        "### Make a copy of the original DataFrame\n",
        "\n",
        "Since we're going to be manipulating the data, we'll make a copy of the original DataFrame and perform our changes there.\n",
        "\n",
        "This will keep the original DataFrame in tact if we need it again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z7-ZgYMDEna"
      },
      "source": [
        "# Make a copy of the original DataFrame to perform edits on\n",
        "df_tmp = df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_RSIgR4DEna"
      },
      "source": [
        "### Add datetime parameters for saledate column\n",
        "\n",
        "\n",
        "\n",
        "We imported the data using `read_csv()` and we asked pandas to parse the dates using `parase_dates=[\"saledate\"]`, we can now access the [different datetime attributes](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.html) of the `saledate` column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMWF-7kXDEnb"
      },
      "source": [
        "# Add datetime parameters for saledate\n",
        "df_tmp[\"saleYear\"] = df_tmp.saledate.dt.year\n",
        "df_tmp[\"saleMonth\"] = df_tmp.saledate.dt.month\n",
        "df_tmp[\"saleDay\"] = df_tmp.saledate.dt.day\n",
        "df_tmp[\"saleDayofweek\"] = df_tmp.saledate.dt.dayofweek\n",
        "df_tmp[\"saleDayofyear\"] = df_tmp.saledate.dt.dayofyear\n",
        "\n",
        "# Drop original saledate\n",
        "df_tmp.drop(\"saledate\", axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSfPEJvJDEnb"
      },
      "source": [
        "We could add more of these style of columns, such as, whether it was the start or end of a quarter but these will do for now.\n",
        "\n",
        "**Challenge:** See what other [datetime attributes](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.html) you can add to `df_tmp` using a similar technique to what we've used above. Hint: check the bottom of the pandas.DatetimeIndex docs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skFRKiKIDEnb"
      },
      "source": [
        "df_tmp.head().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C02UaXB1DEnc"
      },
      "source": [
        "# Check the different values of different columns\n",
        "df_tmp.state.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxwebdeMDEnc"
      },
      "source": [
        "## 5. Modelling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fazUeFcTDEnd"
      },
      "source": [
        "# Check for missing categories and different datatypes\n",
        "df_tmp.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_lmKR3aDEnd"
      },
      "source": [
        "# Check for missing values\n",
        "df_tmp.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T9cliOODEne"
      },
      "source": [
        "## Convert strings to categories\n",
        "\n",
        "One way to help turn all of our data into numbers is to convert the columns with the string datatype into a category datatype.\n",
        "\n",
        "To do this we can use the [pandas types API](https://pandas.pydata.org/pandas-docs/stable/reference/general_utility_functions.html#data-types-related-functionality) which allows us to interact and manipulate the types of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py6tPgCFDEne"
      },
      "source": [
        "df_tmp.head().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n89lt4XiDEnf"
      },
      "source": [
        "pd.api.types.is_string_dtype(df_tmp[\"UsageBand\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FQyLDxRDEnf"
      },
      "source": [
        "# These columns contain strings\n",
        "for label, content in df_tmp.items():\n",
        "    if pd.api.types.is_string_dtype(content):\n",
        "        print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX4nms7BDEng"
      },
      "source": [
        "# This will turn all of the string values into category values\n",
        "for label, content in df_tmp.items():\n",
        "    if pd.api.types.is_string_dtype(content):\n",
        "        df_tmp[label] = content.astype(\"category\").cat.as_ordered()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbeGOjvXDEng"
      },
      "source": [
        "df_tmp.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbBE96mhDEng"
      },
      "source": [
        "df_tmp.state.cat.categories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pPOkeHuDEnh"
      },
      "source": [
        "df_tmp.state.cat.codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5JAvdrcDEnh"
      },
      "source": [
        "All of our data is categorical and thus we can now turn the categories into numbers, however it's still missing values..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emY_tk6iDEnh"
      },
      "source": [
        "df_tmp.isnull().sum()/len(df_tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De1yVP9dDEnh"
      },
      "source": [
        "In the format it's in, it's still good to be worked with, let's save it to file and reimport it so we can continue on.\n",
        "\n",
        "### Save Processed Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSgjV10SDEni"
      },
      "source": [
        "# Save preprocessed data\n",
        "df_tmp.to_csv(\"../data/bluebook-for-bulldozers/train_tmp.csv\",\n",
        "              index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xUjA-d_DEni"
      },
      "source": [
        "# Import preprocessed data\n",
        "df_tmp = pd.read_csv(\"../data/bluebook-for-bulldozers/train_tmp.csv\",\n",
        "                     low_memory=False)\n",
        "df_tmp.head().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i1je2DQDEni"
      },
      "source": [
        "# Check missing values\n",
        "df_tmp.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmiWFAkGDEnj"
      },
      "source": [
        "## Fill missing values\n",
        "\n",
        "1. All of our data has to be numerical\n",
        "2. There can't be any missing values\n",
        "\n",
        "\n",
        "\n",
        "### Filling numerical values first\n",
        "\n",
        "Fill any column with missing values with the median of that column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0KHvCM8DEnj"
      },
      "source": [
        "for label, content in df_tmp.items():\n",
        "    if pd.api.types.is_numeric_dtype(content):\n",
        "        print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQrunAr7DEnj"
      },
      "source": [
        "# Check for which numeric columns have null values\n",
        "for label, content in df_tmp.items():\n",
        "    if pd.api.types.is_numeric_dtype(content):\n",
        "        if pd.isnull(content).sum():\n",
        "            print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMN6FIODDEnk"
      },
      "source": [
        "# Fill numeric rows with the median\n",
        "for label, content in df_tmp.items():\n",
        "    if pd.api.types.is_numeric_dtype(content):\n",
        "        if pd.isnull(content).sum():\n",
        "            # Add a binary column which tells if the data was missing our not\n",
        "            df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n",
        "            # Fill missing numeric values with median since it's more robust than the mean\n",
        "            df_tmp[label] = content.fillna(content.median())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DihgQ5ZDEnk"
      },
      "source": [
        "Why add a binary column indicating whether the data was missing or not?\n",
        "\n",
        "We can easily fill all of the missing numeric values in our dataset with the median. However, a numeric value may be missing for a reason. In other words, absence of evidence may be evidence of absence. Adding a binary column which indicates whether the value was missing or not helps to retain this information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXkUuNSQDEnk"
      },
      "source": [
        "# Check if there's any null values\n",
        "for label, content in df_tmp.items():\n",
        "    if pd.api.types.is_numeric_dtype(content):\n",
        "        if pd.isnull(content).sum():\n",
        "            print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEp5zFXmDEnk"
      },
      "source": [
        "# Check to see how many examples were missing\n",
        "df_tmp.auctioneerID_is_missing.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNzEN0faDEnl"
      },
      "source": [
        "### Filling and turning categorical variables to numbers\n",
        "\n",
        "Now we've filled the numeric values, we'll do the same with the categorical values at the same time as turning them into numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zt2WLSUDEnl"
      },
      "source": [
        "# Check columns which *aren't* numeric\n",
        "for label, content in df_tmp.items():\n",
        "    if not pd.api.types.is_numeric_dtype(content):\n",
        "        print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx0qs17uDEnm"
      },
      "source": [
        "# Turn categorical variables into numbers\n",
        "for label, content in df_tmp.items():\n",
        "    # Check columns which *aren't* numeric\n",
        "    if not pd.api.types.is_numeric_dtype(content):\n",
        "        # Add binary column to inidicate whether sample had missing value\n",
        "        df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n",
        "        # We add the +1 because pandas encodes missing categories as -1\n",
        "        df_tmp[label] = pd.Categorical(content).codes+1        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30tgcu3bDEnm"
      },
      "source": [
        "df_tmp.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0TL1bgZDEnm"
      },
      "source": [
        "df_tmp.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddSsGgUrDEnn"
      },
      "source": [
        "df_tmp.head().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp7w6pyEDEnn"
      },
      "source": [
        "Now all of our data is numeric and there are no missing values, we should be able to build a machine learning model\n",
        "\n",
        "[RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9Xw7X-GDEnn"
      },
      "source": [
        "%%time\n",
        "# Instantiate model\n",
        "model = RandomForestRegressor(n_jobs=-1)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(df_tmp.drop(\"SalePrice\", axis=1), df_tmp.SalePrice)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcBWvmnxDEnn"
      },
      "source": [
        "# Score the model\n",
        "model.score(df_tmp.drop(\"SalePrice\", axis=1), df_tmp.SalePrice)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUjG5edCDEno"
      },
      "source": [
        "### Splitting data into train/valid sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMJ-AbEIDEno"
      },
      "source": [
        "df_tmp.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HILQRHh9DEno"
      },
      "source": [
        "According to the [Kaggle data page](https://www.kaggle.com/c/bluebook-for-bulldozers/data), the validation set and test set are split according to dates.\n",
        "\n",
        "\n",
        "\n",
        "Randomly splitting our data into train and test sets using something like `train_test_split()` wouldn't work.\n",
        "\n",
        "Instead, we split our data into training, validation and test sets using the date each sample occured.\n",
        "\n",
        "In our case:\n",
        "* Training = all samples up until 2011\n",
        "* Valid = all samples form January 1, 2012 - April 30, 2012\n",
        "* Test = all samples from May 1, 2012 - November 2012\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csQYzTa_DEnp"
      },
      "source": [
        "df_tmp.saleYear.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dMVyGFiDEnp"
      },
      "source": [
        "# Split data into training and validation\n",
        "df_val = df_tmp[df_tmp.saleYear == 2012]\n",
        "df_train = df_tmp[df_tmp.saleYear != 2012]\n",
        "\n",
        "len(df_val), len(df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWbXlYWpDEnp"
      },
      "source": [
        "# Split data into X & y\n",
        "X_train, y_train = df_train.drop(\"SalePrice\", axis=1), df_train.SalePrice\n",
        "X_valid, y_valid = df_val.drop(\"SalePrice\", axis=1), df_val.SalePrice\n",
        "\n",
        "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAhgzTJCDEnq"
      },
      "source": [
        "### Building an evaluation function\n",
        "\n",
        "According to Kaggle for the Bluebook for Bulldozers competition, [the evaluation function](https://www.kaggle.com/c/bluebook-for-bulldozers/overview/evaluation) they use is root mean squared log error (RMSLE).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOo3JS4RDEnq"
      },
      "source": [
        "# Create evaluation function (the competition uses Root Mean Square Log Error)\n",
        "from sklearn.metrics import mean_squared_log_error, mean_absolute_error\n",
        "\n",
        "def rmsle(y_test, y_preds):\n",
        "    return np.sqrt(mean_squared_log_error(y_test, y_preds))\n",
        "\n",
        "# Create function to evaluate our model\n",
        "def show_scores(model):\n",
        "    train_preds = model.predict(X_train)\n",
        "    val_preds = model.predict(X_valid)\n",
        "    scores = {\"Training MAE\": mean_absolute_error(y_train, train_preds),\n",
        "              \"Valid MAE\": mean_absolute_error(y_valid, val_preds),\n",
        "              \"Training RMSLE\": rmsle(y_train, train_preds),\n",
        "              \"Valid RMSLE\": rmsle(y_valid, val_preds),\n",
        "              \"Training R^2\": model.score(X_train, y_train),\n",
        "              \"Valid R^2\": model.score(X_valid, y_valid)}\n",
        "    return scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6jfBAfiDEnq"
      },
      "source": [
        "### Testing our model on a subset (to tune the hyperparameters)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNm1wGHWDEnr"
      },
      "source": [
        "len(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EFKN3w0DEnr"
      },
      "source": [
        "\n",
        "Let's alter the number of samples each `n_estimator` in the [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) see's using the `max_samples` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LefswcDMDEnr"
      },
      "source": [
        "# Change max samples in RandomForestRegressor\n",
        "model = RandomForestRegressor(n_jobs=-1,\n",
        "                              max_samples=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6jmF7AxDEnr"
      },
      "source": [
        "Setting `max_samples` to 10000 means every `n_estimator` (default 100) in our `RandomForestRegressor` will only see 10000 random samples from our DataFrame instead of the entire 400,000.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V3iAM_IDEns"
      },
      "source": [
        "%%time\n",
        "# Cutting down the max number of samples each tree can see improves training time\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gca5FsAPDEns"
      },
      "source": [
        "show_scores(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzsdcuRDDEns"
      },
      "source": [
        "### Hyperparameter tuning with RandomizedSearchCV\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15hzQu_iDEnt"
      },
      "source": [
        "%%time\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Different RandomForestClassifier hyperparameters\n",
        "rf_grid = {\"n_estimators\": np.arange(10, 100, 10),\n",
        "           \"max_depth\": [None, 3, 5, 10],\n",
        "           \"min_samples_split\": np.arange(2, 20, 2),\n",
        "           \"min_samples_leaf\": np.arange(1, 20, 2),\n",
        "           \"max_features\": [0.5, 1, \"sqrt\", \"auto\"],\n",
        "           \"max_samples\": [10000]}\n",
        "\n",
        "rs_model = RandomizedSearchCV(RandomForestRegressor(),\n",
        "                              param_distributions=rf_grid,\n",
        "                              n_iter=20,\n",
        "                              cv=5,\n",
        "                              verbose=True)\n",
        "\n",
        "rs_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkWCZIvtDEnt"
      },
      "source": [
        "# Find the best parameters from the RandomizedSearch \n",
        "rs_model.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW4i3dw9DEnt"
      },
      "source": [
        "# Evaluate the RandomizedSearch model\n",
        "show_scores(rs_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po5wxOaMDEnu"
      },
      "source": [
        "### Train a model with the best parameters\n",
        "\n",
        "\n",
        "\n",
        "We'll instantiate a new model with these discovered hyperparameters and reset the `max_samples` back to its original value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qX4Aub3DEnu"
      },
      "source": [
        "%%time\n",
        "# Most ideal hyperparameters\n",
        "ideal_model = RandomForestRegressor(n_estimators=90,\n",
        "                                    min_samples_leaf=1,\n",
        "                                    min_samples_split=14,\n",
        "                                    max_features=0.5,\n",
        "                                    n_jobs=-1,\n",
        "                                    max_samples=None)\n",
        "ideal_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRnkHPlpDEnu"
      },
      "source": [
        "show_scores(ideal_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yvWwLSzDEnu"
      },
      "source": [
        "With these new hyperparameters as well as using all the samples, we can see an improvement to our models performance.\n",
        "\n",
        "You can make a faster model by altering some of the hyperparameters. Particularly by lowering `n_estimators` since each increase in `n_estimators` is basically building another small model.\n",
        "\n",
        "However, lowering of `n_estimators` or altering of other hyperparameters may lead to poorer results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXJRClzWDEnv"
      },
      "source": [
        "%%time\n",
        "# Faster model\n",
        "fast_model = RandomForestRegressor(n_estimators=40,\n",
        "                                   min_samples_leaf=3,\n",
        "                                   max_features=0.5,\n",
        "                                   n_jobs=-1)\n",
        "fast_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4L5WPqFDEnv"
      },
      "source": [
        "show_scores(fast_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg0HoM1PDEnv"
      },
      "source": [
        "### Make predictions on test data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbSAak1WDEnw"
      },
      "source": [
        "df_test = pd.read_csv(\"../data/bluebook-for-bulldozers/Test.csv\",\n",
        "                      parse_dates=[\"saledate\"])\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTmnKRQKDEnw"
      },
      "source": [
        "Ahhh... the test data isn't in the same format of our other data, so we have to fix it. Let's create a function to preprocess our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG-duDe7DEnw"
      },
      "source": [
        "### Preprocessing the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4oaBze1DEnw"
      },
      "source": [
        "def preprocess_data(df):\n",
        "    # Add datetime parameters for saledate\n",
        "    df[\"saleYear\"] = df.saledate.dt.year\n",
        "    df[\"saleMonth\"] = df.saledate.dt.month\n",
        "    df[\"saleDay\"] = df.saledate.dt.day\n",
        "    df[\"saleDayofweek\"] = df.saledate.dt.dayofweek\n",
        "    df[\"saleDayofyear\"] = df.saledate.dt.dayofyear\n",
        "\n",
        "    # Drop original saledate\n",
        "    df.drop(\"saledate\", axis=1, inplace=True)\n",
        "    \n",
        "    # Fill numeric rows with the median\n",
        "    for label, content in df.items():\n",
        "        if pd.api.types.is_numeric_dtype(content):\n",
        "            if pd.isnull(content).sum():\n",
        "                df[label+\"_is_missing\"] = pd.isnull(content)\n",
        "                df[label] = content.fillna(content.median())\n",
        "                \n",
        "        # Turn categorical variables into numbers\n",
        "        if not pd.api.types.is_numeric_dtype(content):\n",
        "            df[label+\"_is_missing\"] = pd.isnull(content)\n",
        "            # We add the +1 because pandas encodes missing categories as -1\n",
        "            df[label] = pd.Categorical(content).codes+1        \n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTitZcNrDEnx"
      },
      "source": [
        "**Question:** Where would this function break?\n",
        "\n",
        "**Hint:** What if the test data had different missing values to the training data?\n",
        "\n",
        "Now we've got a function for preprocessing data, let's preprocess the test dataset into the same format as our training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgC8YIJODEnx"
      },
      "source": [
        "df_test = preprocess_data(df_test)\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv_YgTAvDEnx"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhGnh2lwDEnx"
      },
      "source": [
        "# Make predictions on the test dataset using the best model\n",
        "test_preds = ideal_model.predict(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQkx4sn7DEny"
      },
      "source": [
        "We've found an error and it's because our test dataset (after preprocessing) has 101 columns where as, our training dataset (`X_train`) has 102 columns (after preprocessing).\n",
        "\n",
        "Let's find the difference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTtx6XjlDEny"
      },
      "source": [
        "# We can find how the columns differ using sets\n",
        "set(X_train.columns) - set(df_test.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqWWJRmGDEny"
      },
      "source": [
        "In this case, it's because the test dataset wasn't missing any `auctioneerID` fields.\n",
        "\n",
        "To fix it, we'll add a column to the test dataset called `auctioneerID_is_missing` and fill it with `False`, since none of the `auctioneerID` fields are missing in the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn82aZHDDEnz"
      },
      "source": [
        "# Match test dataset columns to training dataset\n",
        "df_test[\"auctioneerID_is_missing\"] = False\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWU3YaQMDEnz"
      },
      "source": [
        "Now the test dataset matches the training dataset, we should be able to make predictions on it using our trained model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkMzwEsZDEnz"
      },
      "source": [
        "# Make predictions on the test dataset using the best model\n",
        "test_preds = ideal_model.predict(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbc0OFCQDEnz"
      },
      "source": [
        "When looking at the [Kaggle submission requirements](https://www.kaggle.com/c/bluebook-for-bulldozers/overview/evaluation), we see that if we wanted to make a submission, the data is required to be in a certain format. Namely, a DataFrame containing the `SalesID` and the predicted `SalePrice` of the bulldozer.\n",
        "\n",
        "Let's make it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SjSNkWDDEn0"
      },
      "source": [
        "# Create DataFrame compatible with Kaggle submission requirements\n",
        "df_preds = pd.DataFrame()\n",
        "df_preds[\"SalesID\"] = df_test[\"SalesID\"]\n",
        "df_preds[\"SalePrice\"] = test_preds\n",
        "df_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS-Qb1Y2DEn0"
      },
      "source": [
        "# Export to csv...\n",
        "#df_preds.to_csv(\"../data/bluebook-for-bulldozers/predictions.csv\",\n",
        "#                index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}